# Bewertung verschiedener Methoden hinsichtlich ihrer FÃ¤higkeit abstrakte Merkmale aus 2D-Daten zu extrahieren

In diesem Projekt werden mehrere Methoden zur Extraktion von Merkmalen aus Bildern untersucht und miteinander verglichen. Im Mittelpunkt steht dabei die QualitÃ¤t der extrahierten Merkmale, ihre Eignung fÃ¼r die Identifizierung Ã¤hnlicher Bilder und die Anwendbarkeit der Methoden auf verschiedene DatensÃ¤tze.

## ğŸ–¼ï¸ DatensÃ¤tze
Im Repository sind Klassen und Hilfsmethoden fÃ¼r folgende DatensÃ¤tze vorhanden:
- ImageNet: `dataset_utils/imagenet/`
- Places365: `dataset_utils/places365/`
- ArtPlaces: `dataset_utils/artplaces/`

## ğŸ§  Modelle
Das Repository enthÃ¤lt des weiteren Module fÃ¼r verschiedene Modelle:
- Perceptual Loss: `perceptual_loss/`
- Siamese Network: `siamese_network/`
- MoCo: `moco/`
- DINOv2: `dino_v2/`
- CLIP: `clip_model/`

## ğŸ¯ Evaluationsmetriken
FÃ¼r die Bewertung der Ergebnisse wurden folgende Metriken verwendet:
- Accuracy@k: Anteil der korrekt klassifizierten Bilder im VerhÃ¤ltnis zur Gesamtzahl der Bilder
- Precision@k: Anteil der korrekt klassifizierten Bilder innerhalb einer vorhergesagten Klasse
- Recall@k: Anteil der korrekt klassifizierten Bilder innerhalb der jeweiligen Klasse

## ğŸ§ª Ablauf der Experimente
FÃ¼r jede Methode und jeden Datensatz werden die folgenden Schritte durchgefÃ¼hrt:
1. Extraktion der Merkmale
2. EinfÃ¼gen der Features in einen Faiss-Index
3. Suchen der n nÃ¤chsten Nachbarn fÃ¼r jedes Bild eines Datensatzes
4. Bewerten der gefunden Bilder mithilfe verschiedener Metriken

## ğŸ“ Projektstruktur (relevante Dateien/Ordner)
```
â”œâ”€ clip_model/
â”œâ”€ dataset_utils/               # Klassen zum Laden der DatensÃ¤tze
â”‚   â”œâ”€ artplaces/
â”‚   â”œâ”€ imagenet/
â”‚   â””â”€ places365/
â”œâ”€ dino_v2/
â”œâ”€ distance_utils/
â”œâ”€ moco/
â”œâ”€ perceptual_loss/
â”œâ”€ siamese_network/
â”œâ”€ compare_vectors.ipynb
â”œâ”€ confusion_matrix.ipynb
â”œâ”€ evaluation_constants.py      # Konstanten fÃ¼r die Evaluation
â”œâ”€ evaluation_utils.py          # Hilfsfunktionen fÃ¼r die Evaluation
â””â”€ evaluation.ipynb             # Jupyter Notebook fÃ¼r die Evaluation
```

## âš™ï¸ DurchfÃ¼hrung der Experimente

1. AbhÃ¤ngikeiten installieren
    
    ZunÃ¤chst mÃ¼ssen alle AbhÃ¤ngigkeiten installiert werden. ZusÃ¤tzlich ist die Installation von CLIP erforderlich. Weitere Informationen dazu finden sich in der README des Ordners `clip_model/`

2. Konfiguration prÃ¼fen

    In der Datei `evaluation_constants.py` mÃ¼ssen einige Einstellungen angepasst werden:
    - Speicherort fÃ¼r die Ergenisse
    - Speicherort der Modellgewichte

3. Datensatzpfade anpassen

    Des weiteren mÃ¼ssen die Pfade zu den entsprechenden DatensÃ¤tzen in der Datei `evaluation.ipynb` durch die korrekten Pfade ersetzt werden

4. Experimente durchfÃ¼hren

    Die Datei `evaluation.ipynb` muss nun Zelle fÃ¼r Zelle ausgefÃ¼hrt werden.

5. Ergenisse einsehen

    Nach dem AusfÃ¼hren der Experimente werden die Ergebnisse als JSON-Datei im zuvor definierten Ordner abgelegt.
