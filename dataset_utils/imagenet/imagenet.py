import torchvision
from torch.utils import data
import os
import random
from abc import ABC, abstractmethod
import csv
from PIL import Image

import sys
sys.path.append("../")
from dataset_utils import Transforms


class AbstractImageNet(data.Dataset, ABC):
    def __init__(
            self,
            root:str = r"C:\Users\mariu\Documents\Development\Datasets\imagenet-object-localization-challenge",
            split:str = "train",
            transform = Transforms.DEFAULT.value
        ):

        super().__init__()

        if split != "train" and split != "val":
            raise ValueError("Split can only be train or val")

        self.root = root
        self.split = split
        self.transform = transform

        self.class_to_idx = {}
        self.idx_to_class = {}
        self.id_to_idx = {}
        self.id_to_class = {}
        file = open(os.path.join(self.root, "LOC_synset_mapping.txt"), "r")
        for i, line in enumerate(file.readlines()):
            synset_id = line.split()[0]
            c = " ".join(line.split(", ")[0].split()[1:])
            self.class_to_idx[c] = i
            self.idx_to_class[i] = c
            self.id_to_idx[synset_id] = i
            self.id_to_class[synset_id] = c


        image_folder = os.path.join(self.root, "ILSVRC", "Data", "CLS-LOC", split)
        
        self.len = 0
        self.class_to_idxs = {}
        self.imgs = []
        if split == "train":
            synset_ids = os.listdir(image_folder)
            for synset_id in synset_ids:
                l = len(os.listdir(os.path.join(image_folder, synset_id)))
                if l == 0:
                    self.class_to_idxs[self.id_to_class[synset_id]] = {
                        "n": 0,
                        "start": None,
                        "end": None
                    }
                else:
                    self.class_to_idxs[self.id_to_class[synset_id]] = {
                        "n": l,
                        "start": self.len,
                        "end": self.len + l - 1
                    }
                    self.len += l
            
            self.imagenet = torchvision.datasets.ImageFolder(image_folder, transform=transform, allow_empty=True)

            self.imgs = self.imagenet.imgs
        else:
            file = open(os.path.join(self.root, "LOC_val_solution.csv"))
            csv_reader = csv.reader(file)
            _ = next(csv_reader)
            for row in csv_reader:
                image_name, synset_id = row[0], row[1].split()[0]
                self.imgs.append((os.path.join(image_folder, image_name + ".JPEG"), self.id_to_idx[synset_id]))
            self.len = len(self.imgs)
    
    def __len__(self):
        return self.len

    @abstractmethod
    def __getitem__(self, index):
        pass


class ImageNet(AbstractImageNet):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    def __getitem__(self, index):
        if self.split == "train":
            image, label = self.imagenet[index]
        else:
            image_path, label = self.imgs[index]
            image = Image.open(image_path).convert("RGB")

            if self.transform is not None:
                image = self.transform(image)

        return image, label
    
    def getSubset(self, image_num, classes=None):
        if classes == None:
            indices = random.sample(range(0, self.__len__()), min(image_num, self.__len__()))
            return data.Subset(self, indices) #, data.Subset(self.untransformed_image_folder, indices)

        a = image_num // len(classes)
        b = image_num % len(classes)
        images_per_class = [a for _ in range(len(classes) - 1)] + [a + b]

        indices = []

        for l, num in zip(classes, images_per_class):
            if isinstance(l, int):
                l = self.idx_to_class[l]
            start, end = self.class_to_idxs[l]["start"], self.class_to_idxs[l]["end"]
            if start is None or end is None:
                continue
            indices = indices + random.sample(range(start, end+1), min(num, (end+1)-start))
        
        return data.Subset(self, indices) #, data.Subset(self.untransformed_image_folder, indices)


class ImageNet_Triplet(AbstractImageNet):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
    
    def __getitem__(self, index):
        if self.split == "train":
            anchor, anchor_label = self.imagenet[index]

            # select positive
            class_positive = self.idx_to_class[anchor_label]
            start, end = self.class_to_idxs[class_positive]["start"], self.class_to_idxs[class_positive]["end"]
            positive_index = random.randrange(start, end+1)
            positive, positive_label = self.imagenet[positive_index]

            negative_labels = list(range(0, 1000))
            negative_labels.remove(anchor_label)
            random.shuffle(negative_labels)

            for negative_label in negative_labels:
                class_negative = self.idx_to_class[negative_label]
                start, end = self.class_to_idxs[class_negative]["start"], self.class_to_idxs[class_negative]["end"]
                if start is None or end is None:
                    continue
                negative_index = random.randrange(start, end+1)
                negative, negative_label = self.imagenet[negative_index]
            
            raise(RuntimeError("No negative picture found"))
        else:
            anchor_path, anchor_label = self.imgs[index]
            anchor = self._get_image_helper(anchor_path)

            # select positive
            positive_path, positive_label = random.choice([i for i in self.imgs if i[1] == anchor_label])
            positive = self._get_image_helper(positive_path)

            # randomly select a label from negative_labels
            negative_labels = list(range(0, 1000))
            negative_labels.remove(anchor_label)

            # select negative
            negative_path, negative_label = random.choice([i for i in self.imgs if i[1] in negative_labels])
            negative = self._get_image_helper(negative_path)

        return anchor, positive, negative, anchor_label, positive_label, negative_label

    def _get_image_helper(self, image_path):
        image = Image.open(image_path).convert("RGB")

        if self.transform is not None:
            image = self.transform(image)
        
        return image
    
    def getSubset(self, image_num):
        indices = random.sample(range(0, self.__len__()), min(image_num, self.__len__()))
        return data.Subset(self, indices)
