{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subset(source, dest, num_train_images, num_val_images):\n",
    "    os.makedirs(dest)\n",
    "\n",
    "    shutil.copy2(os.path.join(source, \"categories_places365.txt\"), dest)\n",
    "\n",
    "    a = num_train_images // 365\n",
    "    b = num_train_images % 365\n",
    "    train_images_per_class = [a] * 365\n",
    "    for i in range(b):\n",
    "        train_images_per_class[i] += 1\n",
    "\n",
    "    source_train_folder = os.path.join(os.path.join(source, \"data_large_standard\"))\n",
    "    source_val_folder = os.path.join(os.path.join(source, \"val_large\"))\n",
    "    dest_train_folder = os.path.join(os.path.join(dest, \"data_large_standard\"))\n",
    "    dest_val_folder = os.path.join(os.path.join(dest, \"val_large\"))\n",
    "\n",
    "\n",
    "    tqdm_letter_folders = tqdm(os.listdir(source_train_folder), unit=\"letter\")\n",
    "    tqdm_letter_folders.set_description(f\"Copy train images\")\n",
    "    index = 0\n",
    "    source_train_file = open(os.path.join(source, \"places365_train_standard.txt\"))\n",
    "    dest_train_file = open(os.path.join(dest, \"places365_train_standard.txt\"), \"w+\")\n",
    "    rows_train_dict = {}\n",
    "    for row in source_train_file.readlines():\n",
    "        key = (row.split()[0])[1:]\n",
    "        rows_train_dict[key] = row\n",
    "    for letter in tqdm_letter_folders:\n",
    "        index = create_subset_helper(source_train_folder, dest_train_folder, [letter], train_images_per_class, index, rows_train_dict, dest_train_file)\n",
    "    source_train_file.close()\n",
    "    dest_train_file.close()\n",
    "    \n",
    "    # Copy val images\n",
    "    source_val_file = open(os.path.join(source, \"places365_val.txt\"))\n",
    "    dest_val_file = open(os.path.join(dest, \"places365_val.txt\"), \"w+\")\n",
    "\n",
    "    rows_val = [row for row in source_val_file.readlines()]\n",
    "\n",
    "    val_images = os.listdir(source_val_folder)\n",
    "    selected_val_images = random.sample(val_images, min(len(val_images), num_val_images))\n",
    "    os.makedirs(dest_val_folder)\n",
    "\n",
    "    for img in selected_val_images:\n",
    "        src_val_img_path = os.path.join(source_val_folder, img)\n",
    "        dest_val_img_path = os.path.join(dest_val_folder, img)\n",
    "        shutil.copy2(src_val_img_path, dest_val_img_path)\n",
    "\n",
    "        row = next(row for row in rows_val if img in row)\n",
    "        dest_val_file.write(row)\n",
    "    \n",
    "    source_val_file.close()\n",
    "    dest_val_file.close()\n",
    "\n",
    "def create_subset_helper(source, dest, path_parts, train_images_per_class, index, rows_train_dict, dest_train_file):\n",
    "    current_folder = os.path.join(source, *path_parts)\n",
    "    current_folder_content = os.listdir(current_folder)\n",
    "\n",
    "    if os.path.isfile(os.path.join(current_folder, current_folder_content[0])):\n",
    "        # Create corresponding class folder in destination\n",
    "        source_class_path = current_folder\n",
    "        dest_class_path = os.path.join(os.path.join(dest, *path_parts))\n",
    "        os.makedirs(dest_class_path)\n",
    "        \n",
    "        # List all images in the class folder\n",
    "        images = os.listdir(source_class_path)\n",
    "        \n",
    "        # Randomly sample images (or take fewer if not enough images)\n",
    "        selected_images = random.sample(images, min(len(images), train_images_per_class[index]))\n",
    "        \n",
    "        # Copy selected images to destination folder\n",
    "        for img in selected_images:\n",
    "            src_img_path = os.path.join(source_class_path, img)\n",
    "            dest_img_path = os.path.join(dest_class_path, img)\n",
    "            shutil.copy2(src_img_path, dest_img_path)\n",
    "\n",
    "            dest_train_file.write(rows_train_dict[\"/\".join(path_parts + [img])])\n",
    "        \n",
    "        return index + 1\n",
    "    \n",
    "    for folder in current_folder_content:\n",
    "        index = create_subset_helper(source, dest, path_parts + [folder], train_images_per_class, index, rows_train_dict, dest_train_file)\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_subset(r\"C:\\Users\\mariu\\Documents\\Development\\Datasets\\Places365\", r\"C:\\Users\\mariu\\Documents\\Studium\\Praktikum\\Places365_Evaluation_Subset\", 65536, 4096)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
