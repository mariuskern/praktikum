{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "from models import MoCo\n",
    "from loader import TwoCropsTransform, GaussianBlur\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from dataset_utils import ImageNet, Places365, ArtPlaces, ArtPlacesTimesN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814dc882",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f7a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_RUN = True\n",
    "\n",
    "DATASET = \"ArtPlacesTimesN\"\n",
    "N = None\n",
    "match DATASET:\n",
    "    case \"ArtPlacesTimesN\":\n",
    "        N = 12\n",
    "BATCH_SIZE = 64 # 256\n",
    "EPOCHS = 120 # 200\n",
    "CRITERION = \"cross_entropy\"\n",
    "OPTIMIZER = \"sgd\"\n",
    "SCHEDULER = \"step\"\n",
    "match SCHEDULER:\n",
    "    case \"step\":\n",
    "        SCHEDULE = [40, 80] # [120, 160]\n",
    "    case \"cosine\":\n",
    "        SCHEDULE = None\n",
    "\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "LR = 0.01 # 0.03\n",
    "\n",
    "MODEL=\"resnet50\" # resnet50\n",
    "WEIGHTS=\"MOCO\"\n",
    "DIM = 128 # 128\n",
    "K = 4544 # 65536\n",
    "M = 0.999\n",
    "T = 0.07\n",
    "MLP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220e3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # \"architecture\": ARCHITECTURE,\n",
    "    # \"pretrained\": PRETRAINED,\n",
    "    \"dataset\": DATASET,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"learning_rate\": LR,\n",
    "    # \"hidden_units\": HIDDEN_UNITS,\n",
    "    # \"ssim_loss\": USE_SSIM_LOSS,\n",
    "    # \"ssim_loss_scale\": SSIM_SCALE,\n",
    "    # \"perceptual_loss_architecture\": PERCEPTUAL_LOSS_ARCHITECTURE,\n",
    "    # \"perceptual_loss_scale\": SCALE,\n",
    "    \"optimizer\": OPTIMIZER,\n",
    "    # \"optimizer_momentum\": MOMENTUM,\n",
    "    # \"optimizer_weight_decay\": WEIGHT_DECAY,\n",
    "    \"scheduler\": SCHEDULER,\n",
    "    \"schedule\": SCHEDULE,\n",
    "    # \"scheduler_modulo\": SCHEDULE,\n",
    "    # \"scheduler_gamma\": GAMMA,\n",
    "    \"model\": MODEL,\n",
    "    \"weights\": WEIGHTS,\n",
    "    \"dim\": DIM,\n",
    "    \"k\": K,\n",
    "    \"m\": M,\n",
    "    \"t\": T,\n",
    "    \"mlp\": MLP,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057265a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG_RUN:\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec68688",
   "metadata": {},
   "source": [
    "### Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c5e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 4\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(224, scale=(0.2, 1.0)),\n",
    "    torchvision.transforms.RandomGrayscale(p=0.2),\n",
    "    torchvision.transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform = TwoCropsTransform(transform)\n",
    "\n",
    "match DATASET:\n",
    "    case \"ImageNet\":\n",
    "        dataset = ImageNet(root=r\"C:\\Users\\mariu\\Documents\\Studium\\Praktikum\\ImageNet_Subset\", transform=transform)\n",
    "        dataset_val = ImageNet(root=r\"C:\\Users\\mariu\\Documents\\Studium\\Praktikum\\ImageNet_Subset\", split=\"val\", transform=transform)\n",
    "    case \"Places365\":\n",
    "        dataset = Places365(root=r\"C:\\Users\\mariu\\Documents\\Studium\\Praktikum\\Places365_Subset\", transform=transform)\n",
    "        dataset_val = Places365(root=r\"C:\\Users\\mariu\\Documents\\Studium\\Praktikum\\Places365_Subset\", transform=transform, split=\"val\")\n",
    "    case \"ArtPlaces\":\n",
    "        dataset = ArtPlaces(root=r\"C:\\Users\\mariu\\Documents\\Development\\Datasets\\ArtPlaces_13371280\", transform=transform)\n",
    "        dataset_val = ArtPlaces(root=r\"C:\\Users\\mariu\\Documents\\Development\\Datasets\\ArtPlaces_13371280\", transform=transform, split=\"val\")\n",
    "    case \"ArtPlacesTimesN\":\n",
    "        dataset = ArtPlacesTimesN(N, root=r\"C:\\Users\\mariu\\Documents\\Development\\Datasets\\ArtPlaces_13371280\", transform=transform)\n",
    "        dataset_val = ArtPlaces(root=r\"C:\\Users\\mariu\\Documents\\Development\\Datasets\\ArtPlaces_13371280\", transform=transform, split=\"val\")\n",
    "\n",
    "data_loader = data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "data_loader_val = data.DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd83764",
   "metadata": {},
   "source": [
    "### Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e374964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco = MoCo(\n",
    "    transform=None,\n",
    "    model=MODEL,\n",
    "    weights=WEIGHTS,\n",
    "    dim = DIM,\n",
    "    K = K,\n",
    "    m = M,\n",
    "    T = T,\n",
    "    mlp = MLP\n",
    ")\n",
    "\n",
    "moco = moco.train()\n",
    "moco = moco.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dfb5f7",
   "metadata": {},
   "source": [
    "### Modell trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0556410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG_RUN:\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"moco\",\n",
    "        dir=r\"C:\\Users\\mariu\\Desktop\",\n",
    "\n",
    "        # track hyperparameters and run metadata\n",
    "        config=config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a969b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c32ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = os.path.join(r\"C:\\Users\\mariu\\Documents\\Studium\\Praktikum\\Gewichte\", \"moco\", MODEL.lower() + \"_\" + DATASET.lower() + \"_\" + datetime.today().strftime('%Y%m%d_%H%M%S'))\n",
    "os.makedirs(dest)\n",
    "\n",
    "with open(os.path.join(dest, \"constants.json\"), \"w\") as file:\n",
    "    json.dump(config, file)\n",
    "\n",
    "def save_model(epoch=0):\n",
    "    torch.save(moco.state_dict(), os.path.join(dest, \"state_dict_\" + str(epoch) + \".pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9956170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion\n",
    "\n",
    "match CRITERION:\n",
    "    case \"cross_entropy\":\n",
    "        criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "\n",
    "match OPTIMIZER:\n",
    "    case \"sgd\":\n",
    "        optimizer = torch.optim.SGD(\n",
    "            moco.parameters(),\n",
    "            LR,\n",
    "            momentum=MOMENTUM,\n",
    "            weight_decay=WEIGHT_DECAY,\n",
    "        )\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "\n",
    "match SCHEDULER:\n",
    "    case \"step\":\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "    case \"cosine\":\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa3c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    if SCHEDULE is None or epoch in SCHEDULE:\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "    # Train\n",
    "\n",
    "    losses = []\n",
    "    # top1 = []\n",
    "    # top5 = []\n",
    "    \n",
    "    tqdm_data_loader = tqdm(data_loader, unit=\"batch\")\n",
    "    tqdm_data_loader.set_description(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for i, (images, _) in enumerate(tqdm_data_loader):\n",
    "        images[0] = images[0].to(device)\n",
    "        images[1] = images[1].to(device)\n",
    "    \n",
    "        output, target = moco(im_q=images[0], im_k=images[1])\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "        if (i+1) % 10 == 0 and LOG_RUN:\n",
    "            wandb.log({\n",
    "                \"loss\": loss.item(),\n",
    "                # \"acc1\": acc1[0],\n",
    "                # \"acc5\": acc5[0],\n",
    "                \"learning_rate\": scheduler.get_last_lr()[-1], \n",
    "                \"epoch\": epoch + 1,\n",
    "                \"batch\": i + 1,\n",
    "            })\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        # top1.append(acc1[0])\n",
    "        # top5.append(acc5[0])\n",
    "\n",
    "        postfix = {\n",
    "            \"Loss\": loss.item(),\n",
    "            # \"Acc@1\": acc1[0],\n",
    "            # \"Acc@5\": acc5[0],\n",
    "        }\n",
    "\n",
    "        tqdm_data_loader.set_postfix(postfix)\n",
    "    \n",
    "\n",
    "    # Val\n",
    "\n",
    "    val_losses = []\n",
    "    # val_top1 = []\n",
    "    # val_top5 = []\n",
    "\n",
    "    moco.eval()\n",
    "    with torch.no_grad():\n",
    "        tqdm_data_loader_val = tqdm(data_loader_val, unit=\"batch\")\n",
    "        tqdm_data_loader_val.set_description(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        for i, (images, _) in enumerate(tqdm_data_loader_val):\n",
    "            images[0] = images[0].to(device)\n",
    "            images[1] = images[1].to(device)\n",
    "\n",
    "            output, target = moco(im_q=images[0], im_k=images[1])\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "            # val_top1.append(acc1[0])\n",
    "            # val_top5.append(acc5[0])\n",
    "    moco.train()\n",
    "\n",
    "    if LOG_RUN:\n",
    "        wandb.log({\n",
    "            \"loss_avg\": np.mean(losses),\n",
    "            # \"acc1_avg\": np.mean(top1),\n",
    "            # \"acc5_avg\": np.mean(top5),\n",
    "            \"val_loss_avg\": np.mean(val_losses),\n",
    "            # \"val_acc1_avg\": np.mean(val_top1),\n",
    "            # \"val_acc5_avg\": np.mean(val_top5),\n",
    "        })\n",
    "\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        save_model(epoch=epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6db52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG_RUN:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568412a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
